{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "green-symphony",
   "metadata": {},
   "source": [
    "# Create Temporary Tables\n",
    "\n",
    "This tutorial demonstrates how to create tempoary tables in athena using pydbtools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-train",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just run this script to create the source database so we can use it for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import pydbtools as pydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup your own testing area (set foldername = GH username)\n",
    "foldername = \"mratford\"  # GH username\n",
    "foldername = foldername.lower().replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketname = \"alpha-everyone\"\n",
    "s3_base_path = f\"s3://{bucketname}/{foldername}/\"\n",
    "\n",
    "db_name = f\"aws_example_{foldername}\"\n",
    "source_db_base_path = f\"s3://{bucketname}/{foldername}/source_db/\"\n",
    "\n",
    "# Delete all the s3 files in a given path\n",
    "if wr.s3.list_objects(s3_base_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(s3_base_path)\n",
    "\n",
    "# Delete the database if it exists\n",
    "df_dbs = wr.catalog.databases(None)\n",
    "if db_name in df_dbs[\"Database\"].to_list():\n",
    "    print(f\"{db_name} found deleting\")\n",
    "    wr.catalog.delete_database(name=db_name)\n",
    "\n",
    "# Setup source database\n",
    "# Create the database\n",
    "wr.catalog.create_database(db_name)\n",
    "\n",
    "# Iterate through the tables in data/ and write them to our db using awswrangler\n",
    "for table_name in [\"department\", \"employees\", \"sales\"]:\n",
    "\n",
    "    df = pd.read_csv(f\"data/{table_name}.csv\")\n",
    "    table_path = os.path.join(source_db_base_path, table_name)\n",
    "    wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=table_path,\n",
    "        index=False,\n",
    "        dataset=True,  # True allows the other params below i.e. overwriting to db.table\n",
    "        database=db_name,\n",
    "        table=table_name,\n",
    "        mode=\"overwrite\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-processing",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "We are going to create a table that shows total sales per employee using all 3 tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydb.read_sql_query(f\"SELECT * FROM {db_name}.employees LIMIT 5\", ctas_approach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydb.read_sql_query(f\"SELECT * FROM {db_name}.department LIMIT 5\", ctas_approach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydb.read_sql_query(f\"SELECT * FROM {db_name}.sales LIMIT 5\", ctas_approach=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-treaty",
   "metadata": {},
   "source": [
    "pydbtools has a create temp table function that allows you to create tables which you can refer to in a `__temp__` database.\n",
    "\n",
    "**First create a total_sales table:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT employee_id, sum(sales) as total_sales\n",
    "FROM {db_name}.sales\n",
    "GROUP BY employee_id\n",
    "\"\"\"\n",
    "print(sql)\n",
    "pydb.create_temp_table(sql, table_name=\"total_sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-armor",
   "metadata": {},
   "source": [
    "**Then create a table of employee names from the sales department:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT e.employee_id, e.forename, e.surname, d.department_name\n",
    "FROM {db_name}.employees AS e\n",
    "LEFT JOIN {db_name}.department AS d\n",
    "ON e.department_id = d.department_id\n",
    "WHERE e.department_id = 1\n",
    "\"\"\"\n",
    "print(sql)\n",
    "pydb.create_temp_table(sql, table_name=\"sales_employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-market",
   "metadata": {},
   "source": [
    "**Finally return our final table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = f\"\"\"\n",
    "SELECT se.*, ts.total_sales\n",
    "FROM __temp__.sales_employees AS se\n",
    "INNER JOIN __temp__.total_sales AS ts\n",
    "ON se.employee_id = ts.employee_id\n",
    "\"\"\"\n",
    "print(sql)\n",
    "pydb.read_sql_query(sql, ctas_approach=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d0ec29-1bb6-460e-ba3f-8aedaa9bf21d",
   "metadata": {},
   "source": [
    "### Creating a temporary table from a dataframe\n",
    "\n",
    "You can also use an existing dataframe as a table in the temporary database and run SQL queries on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9fd79-1bd3-44d7-8f7e-8db286c55610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/sales.csv\")\n",
    "pydb.dataframe_to_temp_table(df, \"sales\")\n",
    "pydb.read_sql_query(\"select qtr, sum(sales) as sales from __temp__.sales group by qtr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean up\n",
    "\n",
    "# Delete all the s3 files in a given path\n",
    "if wr.s3.list_objects(s3_base_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(s3_base_path)\n",
    "\n",
    "# Delete the database if it exists\n",
    "df_dbs = wr.catalog.databases(None)\n",
    "if db_name in df_dbs[\"Database\"].to_list():\n",
    "    print(f\"{db_name} found deleting\")\n",
    "    wr.catalog.delete_database(name=db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7173160-5ccf-48d1-9d8f-baadd75b5aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python, pydbtools testing",
   "language": "python",
   "name": "pydbtest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
