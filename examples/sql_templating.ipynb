{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "narrow-defeat",
   "metadata": {},
   "source": [
    "# Using SQL templating with pydbtools\n",
    "\n",
    "pydbtools can read SQL files and also rendor SQL with jinja templating this notebook demos both.\n",
    "> Note this functionality is new to pydbtools v4.0.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-daisy",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Just run this script to create the source database so we can use it for our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import pydbtools as pydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup your own testing area (set foldername = GH username)\n",
    "foldername = \"mratford\" # GH username\n",
    "foldername = foldername.lower().replace(\"-\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketname = \"alpha-everyone\"\n",
    "s3_base_path = f\"s3://{bucketname}/{foldername}/\"\n",
    "\n",
    "db_name = f\"aws_example_{foldername}\"\n",
    "source_db_base_path = f\"s3://{bucketname}/{foldername}/source_db/\"\n",
    "\n",
    "# Delete all the s3 files in a given path\n",
    "if wr.s3.list_objects(s3_base_path):\n",
    "    print(\"deleting objs\")\n",
    "    wr.s3.delete_objects(s3_base_path)\n",
    "\n",
    "# Delete the database if it exists\n",
    "df_dbs = wr.catalog.databases(None)\n",
    "if db_name in df_dbs[\"Database\"].to_list():\n",
    "    print(f\"{db_name} found deleting\")\n",
    "    wr.catalog.delete_database(\n",
    "        name=db_name\n",
    "    )\n",
    "\n",
    "# Setup source database\n",
    "# Create the database\n",
    "wr.catalog.create_database(db_name)\n",
    "\n",
    "# Iterate through the tables in data/ and write them to our db using awswrangler\n",
    "for table_name in [\"department\", \"employees\", \"sales\"]:\n",
    "    \n",
    "    df = pd.read_csv(f\"data/{table_name}.csv\")\n",
    "    table_path = os.path.join(source_db_base_path, f\"{table_name}/\")\n",
    "    wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=table_path,\n",
    "        index=False,\n",
    "        dataset=True, # True allows the other params below i.e. overwriting to db.table\n",
    "        database=db_name,\n",
    "        table=table_name,\n",
    "        mode=\"overwrite\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-blair",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "We now have a database with 3 tables. We are joing to write an SQL with [Jinja templating](https://realpython.com/primer-on-jinja-templating/) which we can \"render\" with parameters and then run that query using pydbtools.\n",
    "\n",
    "### Render a template\n",
    "\n",
    "Jinja uses the syntax of two curly brackets for it's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_template = \"\"\"\n",
    "SELECT *\n",
    "FROM {{ db_name }}.{{ table }}\n",
    "\"\"\"\n",
    "print(pydb.render_sql_template(sql_template, {\"db_name\": db_name, \"table\": \"department\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use this rendered SQL to actually return the query.\n",
    "sql = pydb.render_sql_template(sql_template, {\"db_name\": db_name, \"table\": \"department\"})\n",
    "pydb.read_sql_query(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use the same template to read a different table\n",
    "sql = pydb.render_sql_template(sql_template, {\"db_name\": db_name, \"table\": \"sales\"})\n",
    "pydb.read_sql_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-apparel",
   "metadata": {},
   "source": [
    "### Read and render a file\n",
    "\n",
    "So you might be thinking this seems pointless as we can use f-strings. Which is true. But what does come into use is the ability to read in an SQL file and render it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first create a an sql file\n",
    "# as your db_name is dependant on who is running this tutorial we'll use an fstring to create a basic SQL file\n",
    "with open(\"tempfile.sql\", \"w\") as f:\n",
    "    f.write(f\"SELECT * FROM {db_name}.employees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-locking",
   "metadata": {},
   "source": [
    "Now if you open up the file `tempfile.sql` you'll see a simple SQL file and jupyterlab should also give you some syntax colouring for SQL (because it recognises the `.sql` extension).\n",
    "\n",
    "With pydbtools you can read an SQL file and then use that query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = pydb.get_sql_from_file(\"tempfile.sql\")\n",
    "pydb.read_sql_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-michigan",
   "metadata": {},
   "source": [
    "We can use read in and render SQL templates. This means you can store your SQL template as a file and then just parameterise it when reading it in. Then run it.\n",
    "\n",
    "First lets overwrite our new file with the SQL template we originally created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note no f-strings this time. We are using jinja templating\n",
    "with open(\"tempfile.sql\", \"w\") as f:\n",
    "    f.write(\"SELECT * FROM {{ db_name }}.{{ table_name }}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-isolation",
   "metadata": {},
   "source": [
    "Again it is worth looking at the file again (note if it looks the same, close the file in jupyter and reopen it). You should see the same SQL but with the Jinja templating.\n",
    "\n",
    "Now lets read in and rendor our template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = pydb.get_sql_from_file(\"tempfile.sql\", jinja_args={\"db_name\": db_name, \"table_name\": \"department\"})\n",
    "pydb.read_sql_query(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-examination",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Writing your SQL as a file can really helpful to utilise syntax highlighting that you don't get when just writing a string. With jinja templating you can create SQL templates and then parameterise them as you please. \n",
    "\n",
    "Finally, when you start working with a heavy codebase of SQL across multiple users you can use tools like [sqlfluff](https://github.com/sqlfluff/sqlfluff) to lint your SQL files to ensure your team are working to the same standard of SQL. (_SQL fluff also supports Jinja templated SQL files_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-batman",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python, pydbtools",
   "language": "python",
   "name": "pydbtools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
